{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport torch\nimport transformers\nimport unicodedata\nimport pandas as pd\nimport numpy as np\nimport tokenizers\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold,train_test_split\nfrom datasets import Dataset\nimport string\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig,AutoModelForSequenceClassification\nfrom tqdm import tqdm\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import EarlyStoppingCallback\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom sklearn.metrics import f1_score, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-27T09:37:47.853958Z","iopub.execute_input":"2022-09-27T09:37:47.854335Z","iopub.status.idle":"2022-09-27T09:37:56.798612Z","shell.execute_reply.started":"2022-09-27T09:37:47.854225Z","shell.execute_reply":"2022-09-27T09:37:56.797447Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\nif run_type == 'Interactive':\n    print('Wandb in offline mode.')\n    os.environ['WANDB_MODE'] = 'offline'\nprint('Authenticating with wandb.')\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_creds = user_secrets.get_secret(\"wandb\")\n\n!wandb login {wandb_creds}   ","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:37:56.803102Z","iopub.execute_input":"2022-09-27T09:37:56.804083Z","iopub.status.idle":"2022-09-27T09:37:59.365885Z","shell.execute_reply.started":"2022-09-27T09:37:56.804052Z","shell.execute_reply":"2022-09-27T09:37:59.364609Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Wandb in offline mode.\nAuthenticating with wandb.\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/ecommerce-text-classification/ecommerceDataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:37:59.368785Z","iopub.execute_input":"2022-09-27T09:37:59.369197Z","iopub.status.idle":"2022-09-27T09:38:00.103026Z","shell.execute_reply.started":"2022-09-27T09:37:59.369156Z","shell.execute_reply":"2022-09-27T09:38:00.102037Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=df.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:00.105788Z","iopub.execute_input":"2022-09-27T09:38:00.106147Z","iopub.status.idle":"2022-09-27T09:38:00.123903Z","shell.execute_reply.started":"2022-09-27T09:38:00.106109Z","shell.execute_reply":"2022-09-27T09:38:00.122881Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"new_row={'Household':'Household','Paper Plane Design Framed Wall Hanging Motivational Office Decor Art Prints (8.7 X 8.7 inch) - Set of 4 Painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch. This painting is ready to hang, you would be proud to possess this unique painting that is a niche apart. We use only the most modern and efficient printing technology on our prints, with only the and inks and precision epson, roland and hp printers. This innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime. We print solely with top-notch 100% inks, to achieve brilliant and true colours. Due to their high level of uv resistance, our prints retain their beautiful colours for many years. Add colour and style to your living space with this digitally printed painting. Some are for pleasure and some for eternal bliss.so bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and family.it would be treasured forever by whoever your lucky recipient is. Liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home, office or any room.':'Paper Plane Design Framed Wall Hanging Motivational Office Decor Art Prints (8.7 X 8.7 inch) - Set of 4 Painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch. This painting is ready to hang, you would be proud to possess this unique painting that is a niche apart. We use only the most modern and efficient printing technology on our prints, with only the and inks and precision epson, roland and hp printers. This innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime. We print solely with top-notch 100% inks, to achieve brilliant and true colours. Due to their high level of uv resistance, our prints retain their beautiful colours for many years. Add colour and style to your living space with this digitally printed painting. Some are for pleasure and some for eternal bliss.so bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and family.it would be treasured forever by whoever your lucky recipient is. Liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home, office or any room.'}\ndf = df.append(pd.DataFrame([new_row],index=[0],columns=df.columns))\ndf.columns=[\"Categories\",\"Description\"]\ndf=df.reset_index().drop('index',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:00.126197Z","iopub.execute_input":"2022-09-27T09:38:00.126870Z","iopub.status.idle":"2022-09-27T09:38:00.146108Z","shell.execute_reply.started":"2022-09-27T09:38:00.126834Z","shell.execute_reply":"2022-09-27T09:38:00.145031Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df['Categories'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:00.147505Z","iopub.execute_input":"2022-09-27T09:38:00.147846Z","iopub.status.idle":"2022-09-27T09:38:00.162623Z","shell.execute_reply.started":"2022-09-27T09:38:00.147811Z","shell.execute_reply":"2022-09-27T09:38:00.161556Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array(['Household', 'Books', 'Clothing & Accessories', 'Electronics'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df['Description'][25000]","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:00.164379Z","iopub.execute_input":"2022-09-27T09:38:00.165007Z","iopub.status.idle":"2022-09-27T09:38:00.171896Z","shell.execute_reply.started":"2022-09-27T09:38:00.164972Z","shell.execute_reply":"2022-09-27T09:38:00.170809Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'the princess saves herself in this one (Women Are Some Kind of Magic 1) Review \"It blends fairy tale lore with real-life musings for a beautiful result.\"\\xa0(Lindsay E. Mack, Romper)\"As a whole, the collection acts as a tribute to all women who have ever needed a boost of empowerment and inspiration.\"\\xa0(Madison Breaux, V Magazine)\"...Amanda Lovelace dives into the topics of modern feminism and empowerment...Read if you\\'ve ever thought about love, loss, who you are, and what you want. (So...all of us.)\"\\xa0(Abigail Yonker, The Everygirl)\"This is the book to read if you are on the path to writing your own ending and finding yourself, even when the road to accomplishment is rocky.\"\\xa0(Dominique Etzel, Alloy)\"Similar in style—written in straightforward and uncomplicated verse, and content—grappling with themes of female power, love and loss, failure and redemption, pain and healing, poet Amanda Lovelace\\'s\\xa0The Princess Saves Herself in this One\\xa0is similar to Kaur\\'s\\xa0Milk and Honey\\xa0in another way as well: both books were self-published before going completely viral among readers.\"\\xa0(E. CE Miller, Bustle)\"The perfect poetry opener for any fairytale lover and feminist...\"\\xa0(Kerri Jarema, Bustle)\"15 Books You\\'ll Want To Read Over And Over Again\"\\xa0(Zoraida CÃ³rdova, Bustle)\"18 Literary Quotes Every Feminist Needs to Read Right Now\"\\xa0#5 \"the only thing / required / to be / a woman / is to / identify as one. / - period, end of story.\"\\xa0\\xa0(E. CE Miller, Bustle)\"14 New Books You Definitely Need to Have on Your Radar in February [2017]\"\\xa0(Ryan Roschke, PopSugar) \\t\\t\\t\\t    \\t \\t\\t\\t\\t\\t About the Author growing up a word-devourer & avid fairytale lover, it was only natural that amanda lovelace began writing books of her own, & so she did. when she isn’t reading or writing, she can be found waiting for pumpkin spice coffee to come back into season & binge-watching Gilmore girls. (before you ask: team jess all the way.) the lifelong poetess & storyteller currently lives in new jersey with her spouse, their bunnycat, & a combined book collection so large it will soon need its own home. she has her B.A. in English literature with a minor in sociology. her first collection, the princess saves herself in this one, won the Goodreads choice award for best poetry\\xa0&\\xa0is a USA TODAY\\xa0&\\xa0Publishers Weekly bestseller.'"},"metadata":{}}]},{"cell_type":"code","source":"def encoding(text):\n    text= unicodedata.normalize(\"NFKD\",text)\n    \"\"\"\n        Remove unicoded data\n    \"\"\"\n    return text\ndef remove_URL(text):\n    \"\"\"\n        Remove URLs \n    \"\"\"\n    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\ndef remove_non_ascii(text):\n    \"\"\"\n        Remove non-ASCII characters \n    \"\"\"\n    return re.sub(r'[^\\x00-\\x7f]',r'', text)\ndef remove_html(text):\n    \"\"\"\n        Remove the html \n    \"\"\"\n    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n    return re.sub(html, \"\", text)\ndef remove_punct(text):\n    \"\"\"\n        Remove the punctuation\n    \"\"\"\n#     return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n    return text.translate(str.maketrans('', '', string.punctuation))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:00.173740Z","iopub.execute_input":"2022-09-27T09:38:00.174007Z","iopub.status.idle":"2022-09-27T09:38:00.182408Z","shell.execute_reply.started":"2022-09-27T09:38:00.173983Z","shell.execute_reply":"2022-09-27T09:38:00.181373Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df['Description']=df['Description'].apply(encoding)\ndf['Description']=df['Description'].apply(lambda x: x.lower())\ndf['Description']=df['Description'].apply(remove_URL)\ndf['Description']=df['Description'].apply(remove_non_ascii)\ndf['Description']=df['Description'].apply(remove_html)\ndf['Description']=df['Description'].apply(remove_punct)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:00.183981Z","iopub.execute_input":"2022-09-27T09:38:00.184336Z","iopub.status.idle":"2022-09-27T09:38:01.520547Z","shell.execute_reply.started":"2022-09-27T09:38:00.184299Z","shell.execute_reply":"2022-09-27T09:38:01.519573Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df['Description'][10]","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:01.525642Z","iopub.execute_input":"2022-09-27T09:38:01.525928Z","iopub.status.idle":"2022-09-27T09:38:01.532644Z","shell.execute_reply.started":"2022-09-27T09:38:01.525903Z","shell.execute_reply":"2022-09-27T09:38:01.531653Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'paper plane design starry night vangoh wall art canvas painting large size rolled canvas art print 36 x 48 we use only the most modern and efficient printing technology on our canvases with only the best and original inks and precision epson roland and hp printers this innovative hd printing technique results in durable and spectacular looking prints of the highest quality that last a lifetime we print solely with topnotch inks to achieve brilliant and true colours due to their high level of uv resistance our canvas prints retain their beautiful colours for many years our canvases contain high levels of white to ensure that the colours of your original image are reproduced exactly with brilliant tones add colour and style to your living space with this digitally printed canvas painting some gifts are for pleasure and some for eternal blissso bring home this elegant canvas print that is lushed with rich colors that makes it nothing but sheer elegance to be gifted to your friends and familyit would be treasured forever by whoever your lucky recipient is liven up your place with these intriguing paintings on canvas that are high definition hd graphic digital prints for home office or any room a perfect size of 36 inches x 48 inches suits every size of space and are a great match with every architectural setting we prove raw canvas prints with special left extra margins for any type of framing required which you can get done as you please art comes in a safe delivery tube prints are made using latest technology and original inks to get a perfect colour and long lasting design'"},"metadata":{}}]},{"cell_type":"code","source":"min_length=df['Description'].str.len().min()\nmax_length=df['Description'].str.len().max()\naverage_length=df['Description'].str.len().mean()\nmedian_length=df['Description'].str.len().median()\nprint(\"Min_Length :\",min_length)\nprint(\"Max_Length :\",max_length)\nprint(\"Mean_Length :\",average_length.round(0).astype(int))\nprint(\"Median_length :\",median_length.astype(int))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:01.534512Z","iopub.execute_input":"2022-09-27T09:38:01.535180Z","iopub.status.idle":"2022-09-27T09:38:01.613842Z","shell.execute_reply.started":"2022-09-27T09:38:01.535145Z","shell.execute_reply":"2022-09-27T09:38:01.612888Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Min_Length : 3\nMax_Length : 48994\nMean_Length : 690\nMedian_length : 470\n","output_type":"stream"}]},{"cell_type":"code","source":"df['ncharacters'] = df['Description'].str.len()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:01.615356Z","iopub.execute_input":"2022-09-27T09:38:01.615988Z","iopub.status.idle":"2022-09-27T09:38:01.636940Z","shell.execute_reply.started":"2022-09-27T09:38:01.615952Z","shell.execute_reply":"2022-09-27T09:38:01.636002Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (22,5))\nsns.distplot(df['ncharacters'])\nplt.axvline(x = average_length, color = 'red')\nplt.axvline(x = median_length, color = 'green')\nplt.title('Character Count')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:01.638791Z","iopub.execute_input":"2022-09-27T09:38:01.639180Z","iopub.status.idle":"2022-09-27T09:38:02.522196Z","shell.execute_reply.started":"2022-09-27T09:38:01.639126Z","shell.execute_reply":"2022-09-27T09:38:02.521198Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Character Count')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1584x360 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABREAAAFNCAYAAACXASiAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5lElEQVR4nO3dfZhdd13v/fd37z0zmTy3SUjapDSFhpb0ICi1gKgHqUA5KlVPuSkIVm+Uc58DRw+cSy3e3ggcewTvI/gEKhzQgmBbKg8Rq1AoiCj0CYrSh7ShD7SlD0maSZpMsmf23t/zx16TboZ5SjJ79sxe79d15Zq1f2ut3/qtmVkXw6ff3/pFZiJJkiRJkiRJ06n0egCSJEmSJEmSFjdDREmSJEmSJEkzMkSUJEmSJEmSNCNDREmSJEmSJEkzMkSUJEmSJEmSNCNDREmSJEmSJEkzMkSUJEnqcxHx1oj4q16PQ5IkSUuXIaIkSVIfiIhXRcRNEXEwIh6KiL+PiB/u9bg6RcQvRMSXu9DvKRHxgeK+H4+IOyLibRGxYr6vNem6hrOSJKk0DBElSZKWuIh4E/AHwP8ENgJPBt4LXNiFa9Xmu88TuXZEnAx8BRgGnpeZq4AXAWuBpy7oACVJkvqYIaIkSdISFhFrgLcDr8/Mj2fmocwcz8y/zcxf6zh0MCI+VFTq3RoR53b0cWlEfKvYd1tE/EzHvl+IiH+OiHdHxF7grRHx1Ii4LiL2RsSeiPhIRKztOOe0iPh4ROwujvmTiHg68GfA84pqyZHi2KGI+F8R8e2IeCQi/iwihot9L4iIByLiNyLiYeAvpvgWvAl4HHh1Zt4LkJn3Z+avZua/Fv38UETcGBH7i68/1DHWeyPixzs+H60ujIitEZERcUkxvj0R8f8W+y4AfhN4RXE/3zjmH54kSdISYogoSZK0tD0PWAZ8YpbjXgZcQbtCbwfwJx37vgX8CLAGeBvwVxFxSsf+5wB3065yvAwI4HeBU4GnA6cBbwWIiCrwaeA+YCuwGbgiM28H/h/gK5m5MjPXFn2/A3ga8CzgzOL4t3RcexNwMnA68Lop7uvHgY9nZmuqmy4qFf8O+CNgHfAu4O8iYt1Ux0/jh4GzgPOBt0TE0zPzH2hXfl5Z3M8zj6E/SZKkJccQUZIkaWlbB+zJzMYsx305M6/JzCbwYeBo6JWZH8vM72RmKzOvBO4Czus49zuZ+ceZ2cjMw5m5KzOvzcx6Zu6mHcz9++LY82iHi79WVEUeycwp34MYEUE7GHxjZj6WmY/TDuYu7jisBfx2ca3D09z/QzPc908Ad2Xmh4vx/zVwB/BTM5wz2duK+/4G8A06vneSJEll0bN32kiSJGle7AXWR0RtliDx4Y7tUWDZxDkR8fO0pwVvLfavBNZ3HH9/Z0cRsRH4Q9rVi6to/4fpfcXu04D75hBqAmwAlgM3t/PEdvdAteOY3Zl5ZIY+9gKnzLD/VNpVkZ3uo13xOFeTv3crj+FcSZKkvmAloiRJ0tL2FaAO/PTxnBwRpwPvB94ArCumGX+Tdpg3ISed9j+Ltmdk5mrg1R3H3w88eZoFWCb3swc4DJyTmWuLf2syc+UM50z2OeBnImK6v2u/Q3sqdKcnAw8W24doB5kTNs1yvU6zjU2SJKlvGCJKkiQtYZm5n/Y7BN8TET8dEcsjYiAiXhoRvzeHLlbQDsN2A0TELwL/bpZzVgEHgf0RsRnoXMDlBtrTi98RESsiYllEPL/Y9wiwJSIGi7G3aAeY746IJxXX3xwRL5nDuCe8C1gNXF4EohN9vCsivg+4BnhaRLwqImoR8QpgO+33NgLcAlxcfM/OBS46hms/AmydIcCUJEnqG/7BI0mStMRl5u/Tno78W7TDwPtpVxZ+cg7n3gb8Pu2KxkeAZwD/PMtpbwN+ANhPe9GSj3f016T9vsEzgW8DDwCvKHZfB9wKPBwRe4q23wB2AV+NiAO0KwvPmm3cHdd7DPghYBy4PiIeBz5fjG1XZu4FfhL477SnPv868JOZOXH9/w94Ku3p2G8DPjrXawMfK77ujYivHcN5kiRJS05kOgtDkiRJkiRJ0vSsRJQkSZIkSZI0I0NESZIkSZIkSTMyRJQkSZIkSZI0I0NESZIkSZIkSTMyRJQkSZIkSZI0o1qvB9BL69evz61bt/Z6GIvWzr07AThr3Vkdje02zjprijMkSZIkSZK0VN188817MnPDVPtKHSJu3bqVm266qdfDWLRe8JcvAOCLv/DFjsZ2G1/8IpIkSZIkSeofEXHfdPuczixJkiRJkiRpRoaIkiRJkiRJkmZkiChJkiRJkiRpRoaIkiRJkiRJkmZkiChJkiRJkiRpRoaIkiRJkiRJkmZkiChJkiRJkiRpRoaIkiRJkiRJkmZkiChJkiRJkiRpRoaIkiRJkiRJkmZkiCh+9+9v57O3PtzrYUiSJEmSJGmRMkQUV9xwP5/4+oO9HoYkSZIkSZIWKUNEUW80uWfPoV4PQ5IkSZIkSYuUIWLJZSb1Rov79o6Smb0ejiRJkiRJkhYhQ8SSG28mmXB4vMnux+u9Ho4kSZIkSZIWIUPEkqs3mke379072sORSJIkSZIkabHqaogYERdExM6I2BURl06xfygiriz2Xx8RWzv2vblo3xkRL+lo/2BEPBoR35zU18kRcW1E3FV8Pamb99Yv6o3W0e179/peREmSJEmSJH2vroWIEVEF3gO8FNgOvDIitk867LXAvsw8E3g38M7i3O3AxcA5wAXAe4v+AP6yaJvsUuDzmbkN+HzxWbPoDBHvM0SUJEmSJEnSFLpZiXgesCsz787MMeAK4MJJx1wIXF5sXw2cHxFRtF+RmfXMvAfYVfRHZn4JeGyK63X2dTnw0/N4L32rPu50ZkmSJEmSJM2smyHiZuD+js8PFG1THpOZDWA/sG6O5062MTMfKrYfBjYe37DLZaISMQLu3WMloiRJkiRJkr5XXy6skpkJ5FT7IuJ1EXFTRNy0e/fuBR7Z4jMRIj755OXct3eU9rdOkiRJkiRJekI3Q8QHgdM6Pm8p2qY8JiJqwBpg7xzPneyRiDil6OsU4NGpDsrM92XmuZl57oYNG+Z4K/1rYjrz0zau4mC9wd5DYz0ekSRJkiRJkhabboaINwLbIuKMiBikvVDKjknH7AAuKbYvAq4rqgh3ABcXqzefAWwDbpjlep19XQJ8ah7uoe9NVCKetXEV4OIqkiRJkiRJ+l5dCxGLdxy+AfgMcDtwVWbeGhFvj4iXFYd9AFgXEbuAN1GsqJyZtwJXAbcB/wC8PjObABHx18BXgLMi4oGIeG3R1zuAF0XEXcCPF581i4kQ8Wmb2iHivXtcXEWSJEmSJEnfrdbNzjPzGuCaSW1v6dg+Arx8mnMvAy6bov2V0xy/Fzj/RMZbRvVGezrzU9avoFoJKxElSZIkSZL0PfpyYRXNXX28XYm4almNzWuHuWevlYiSJEmSJEn6boaIJTfWbIeIQ7Uqp69bbiWiJEmSJEmSvochYslNrM48VKuwdd0K7tlziPbaNpIkSZIkSVKbIWLJTSysMjRQYev6FTx+pMHI6HiPRyVJkiRJkqTFxBCx5CZCxMFqha3rlgNwr1OaJUmSJEmS1MEQseTqjSa1SlCrVjh93QoA7nNxFUmSJEmSJHUwRCy5+niLwVr71+C0k4eJsBJRkiRJkiRJ380QseTqjRZDRYg4VKty6pph7t1jiChJkiRJkqQnGCKWXL3RZKhWPfp56/rl3Ot0ZkmSJEmSJHUwRCy5eqPF0MATvwanr1vBfU5nliRJkiRJUgdDxJKrjz8xnRlg67rl7BsdZ//oeA9HJUmSJEmSpMXEELHkvmc688QKzY9ZjShJkiRJkqQ2Q8SS61xYBWDr+naI6HsRJUmSJEmSNMEQseQmvxPxyScvB3CFZkmSJEmSJB1liFhyk6czLxuocsqaZdzr4iqSJEmSJEkqGCKW3OSFVQBOX7ec+5zOLEmSJEmSpIIhYslNficitBdXuc9KREmSJEmSJBUMEUtu8nRmgNPXrWDPwTGarezRqCRJkiRJkrSYGCKW3OSFVQC2rmsvrnJkvNmLIUmSJEmSJGmRMUQsuaneibh1/QoAjjRavRiSJEmSJEmSFhlDxBLLzGmmM1uJKEmSJEmSpCcYIpZYo5W0ku+pRFw+WONJq4YMESVJkiRJkgQYIpZavZiuPPmdiNBeobk+7nRmSZIkSZIkGSKW2thEiDhpOjO0pzRbiShJkiRJkiQwRCy1eqMdEk6ezgztxVXGmi1amQs9LEmSJEmSJC0yhoglNjFdearpzE8sruKUZkmSJEmSpLIzRCyx+gzTmdevHAJgvGmIKEmSJEmSVHaGiCU203Tmk5YPAu0VnCVJkiRJklRuhoglNlMl4knLBwBoWIkoSZIkSZJUeoaIJTbTOxHXTlQiNq1ElCRJkiRJKjtDxBKbaTrzYK1CtRKMt6xElCRJkiRJKjtDxBKbaTozQK1SsRJRkiRJkiRJhohlNlGJODhFJSJArRourCJJkiRJkiRDxDI7+k7E6ULESriwiiRJkiRJkgwRy+yJ6cxT/xoMVCtWIkqSJEmSJMkQscyOLqwyMN07Ea1ElCRJkiRJkiFiqc06nbmoRDRIlCRJkiRJKjdDxBKrN1pUol1xOJWJ9v2HxxdyWJIkSZIkSVpkDBFLrN5oMlSrEjFNiFhtt+8bNUSUJEmSJEkqM0PEEqs3WgwNTP8rUKu2942Mji3UkCRJkiRJkrQIGSKWWH28Ne37EAEGKlYiSpIkSZIkqcshYkRcEBE7I2JXRFw6xf6hiLiy2H99RGzt2Pfmon1nRLxktj4j4vyI+FpE3BIRX46IM7t5b/1gYjrzdCYqEfdZiShJkiRJklRqXQsRI6IKvAd4KbAdeGVEbJ902GuBfZl5JvBu4J3FuduBi4FzgAuA90ZEdZY+/xT4ucx8FvBR4Le6dW/9ot6YuRJxYmEVpzNLkiRJkiSVWzcrEc8DdmXm3Zk5BlwBXDjpmAuBy4vtq4Hzo73Kx4XAFZlZz8x7gF1FfzP1mcDqYnsN8J0u3VffmO2diNVKEBFOZ5YkSZIkSSq5Whf73gzc3/H5AeA50x2TmY2I2A+sK9q/OunczcX2dH3+EnBNRBwGDgDPnYd76GuzTWeGdjWilYiSJEmSJEnl1k8Lq7wR+A+ZuQX4C+BdUx0UEa+LiJsi4qbdu3cv6AAXm9kWVgGoVYN9h6xElCRJkiRJKrNuhogPAqd1fN5StE15TETUaE9D3jvDuVO2R8QG4JmZeX3RfiXwQ1MNKjPfl5nnZua5GzZsOJ776htjzdlDxIFKxYVVJEmSJEmSSq6b05lvBLZFxBm0w7+LgVdNOmYHcAnwFeAi4LrMzIjYAXw0It4FnApsA24AYpo+9wFrIuJpmXkn8CLg9i7e25L30eu/zSMHjtBsJR+9/ttTHvPogTrNVnLv3kNHjzn/QB2Az09zzque8+TuDFiSJEmSJEk907UQsXjH4RuAzwBV4IOZeWtEvB24KTN3AB8APhwRu4DHaIeCFMddBdwGNIDXZ2YTYKo+i/ZfBv4mIlq0Q8X/u1v31i8azTy6AvN0KpVgdKy5QCOSJEmSJEnSYtTNSkQy8xrgmkltb+nYPgK8fJpzLwMum0ufRfsngE+c4JBLpdFKatWZpzNXA0bHmmQm7YWzJUmSJEmSVDb9tLCKjtF4szWnSsRmKxlrtBZoVJIkSZIkSVpsDBFLrNFKBmatRGyHjE5pliRJkiRJKi9DxBJrzLESEQwRJUmSJEmSyswQsaSaraSVUKvOEiIerURsLMSwJEmSJEmStAgZIpZUs5UA1CqzTGe2ElGSJEmSJKn0DBFLqtFsL5QyWyXiEyGilYiSJEmSJEllZYhYUuNFJeLALJWIE69MtBJRkiRJkiSpvAwRS2qulYhBsGygYogoSZIkSZJUYoaIJdWYeCdidfZfgeWDNaczS5IkSZIklZghYkk1mhMLq8xciQiwfLBqJaIkSZIkSVKJGSKWVKNVTGc2RJQkSZIkSdIsDBFLarzpdGZJkiRJkiTNjSFiSR1LJeKwlYiSJEmSJEmlZohYUkffiTjL6szQns5cb7RoFouxSJIkSZIkqVwMEUtqohJxoDK36cyAU5olSZIkSZJKyhCxpI61EhFwSrMkSZIkSVJJGSKW1HjrWBZWMUSUJEmSJEkqM0PEkmo0576wysR05sNOZ5YkSZIkSSolQ8SSaraczixJkiRJkqS5MUQsqfFmEkA15h4iHjJElCRJkiRJKiVDxJJqtFrUqkHMIUQcrFaoVsLVmSVJkiRJkkrKELGkGs2kVpnbjz8iWD5YdTqzJEmSJElSSRkiltREJeJcGSJKkiRJkiSVlyFiSbUrEY8lRKw5nVmSJEmSJKmkDBFLaryV1Kpz//FbiShJkiRJklRehogl1Wi2GDimSkRDREmSJEmSpLIyRCypxjFXItY4PNYAsnuDkiRJkiRJ0qJkiFhSjWbrGN+JWKWV0DJDlCRJkiRJKh1DxJJqVyIe28IqAK00RZQkSZIkSSobQ8SSaq/OfGwLqwA0LUWUJEmSJEkqHUPEkhpvto6xErEdIlqJKEmSJEmSVD6GiCXVaCUDx1SJ2J7ObCWiJEmSJElS+RgillTjuCsRuzUiSZIkSZIkLVaGiCXVaOUxrc48PFglsBJRkiRJkiSpjAwRS6rRTGrVuf/4KxEsG6j6TkRJkiRJkqQSMkQsoWYraeaxVSJCe0qzlYiSJEmSJEnlY4hYQmONFsAxVSJCO0S0ElGSJEmSJKl8DBFLqN5oAhxHJWLNSkRJkiRJkqQSMkQsofrRSsRjn87canVjRJIkSZIkSVrMDBFLqD7eTgIHKsc+nbnpdGZJkiRJkqTSMUQsobFmMZ35GCsRhwdrZCaJQaIkSZIkSVKZdDVEjIgLImJnROyKiEun2D8UEVcW+6+PiK0d+95ctO+MiJfM1me0XRYRd0bE7RHxK928t6XsSFGJWDuOSkSAlu9FlCRJkiRJKpU5pUgR8fGI+ImImHPqFBFV4D3AS4HtwCsjYvukw14L7MvMM4F3A+8szt0OXAycA1wAvDciqrP0+QvAacDZmfl04Iq5jrVsTuSdiABNM0RJkiRJkqRSmWso+F7gVcBdEfGOiDhrDuecB+zKzLszc4x2qHfhpGMuBC4vtq8Gzo+IKNqvyMx6Zt4D7Cr6m6nP/wy8PTNbAJn56BzvrXSOrs58zCFiDbASUZIkSZIkqWzmFCJm5ucy8+eAHwDuBT4XEf8SEb8YEQPTnLYZuL/j8wNF25THZGYD2A+sm+Hcmfp8KvCKiLgpIv4+IrbN5d7KaKIS8XgWVgFcXEWSJEmSJKlkjmV68jraU4Z/Cfg68Ie0Q8VruzKyYzcEHMnMc4H3Ax+c6qCIeF0RNN60e/fuBR3gYjGxOvPxTme2ElGSJEmSJKlc5vpOxE8A/wQsB34qM1+WmVdm5n8FVk5z2oO031E4YUvRNuUxEVED1gB7Zzh3pj4fAD5ebH8C+L6pBpWZ78vMczPz3A0bNkwz9P52dDrzMVcitqczW4koSZIkSZJULnNNkd6fmdsz83cz8yFor6wMUFT+TeVGYFtEnBERg7QXStkx6ZgdwCXF9kXAdZmZRfvFxerNZwDbgBtm6fOTwI8V2/8euHOO91Y6x7uwymCtQkRYiShJkiRJklQytTke9zvANZPavkJ7OvOUMrMREW8APgNUgQ9m5q0R8XbgpszcAXwA+HBE7AIeox0KUhx3FXAb0ABen5lNgKn6LC75DuAjEfFG4CDtadeawtEQsXJsISJAJVydWZIkSZIkqWxmDBEjYhPthUuGI+L7gYnUaTXtqc0zysxrmBQ+ZuZbOraPAC+f5tzLgMvm0mfRPgL8xGxjEtTH29OZB6rHNp0ZoFqxElGSJEmSJKlsZqtEfAntxVS2AO/qaH8c+M0ujUlddmKViOE7ESVJkiRJkkpmxhAxMy8HLo+I/5iZf7NAY1KXTYSI1eMIEauVOHq+JEmSJEmSymG26cyvzsy/ArZGxJsm78/Md01xmha5eqNJrRJEHHuIWKtUONRs0sqkchznS5IkSZIkaemZbTrziuLrym4PRAunPt465pWZJ7TPSw7WG6xeNjC/A5MkSZIkSdKiNNt05j8vvr5tYYajhVBvtBioHPuiKvDEexT3j44bIkqSJEmSJJXEnJKkiPi9iFgdEQMR8fmI2B0Rr+724NQd9Ubz+CsRixBx5PD4fA5JkiRJkiRJi9hcy9FenJkHgJ8E7gXOBH6tW4NSd9UbLWrHW4lYbZ+33xBRkiRJkiSpNOaaJE1Me/4J4GOZub9L49ECOJF3IlYCIoL9o2PzPCpJkiRJkiQtVrMtrDLh0xFxB3AY+M8RsQE40r1hqZsmVmc+PkGtEk5nliRJkiRJKpE5VSJm5qXADwHnZuY4cAi4sJsDU/fUG62j05KPR60aTmeWJEmSJEkqkblWIgKcDWyNiM5zPjTP49ECqDdaDBzndGaAWqXCyKghoiRJkiRJUlnMKUSMiA8DTwVuAZpFc2KIuCTVx5tUj3NhFYBqJThYb9BonlhFoyRJkiRJkpaGuVYingtsz8zs5mC0MMaaLVYMHksR6nebWJRl/+Fx1q0cmq9hSZIkSZIkaZGaaxnZN4FN3RyIFk59/MSnMwO+F1GSJEmSJKkk5lqOth64LSJuAOoTjZn5sq6MSl1Vb7SOBoHHY2JlZ1doliRJkiRJKoe5hohv7eYgtLDqjebRKcnHY+JcF1eRJEmSJEkqhzmFiJn5jxFxOrAtMz8XEcuBaneHpm450UrEIFgxWHU6syRJkiRJUknMKUmKiF8Grgb+vGjaDHyyS2NSF2UmY43WCVUiAqxZPsD+w2PzNCpJkiRJkiQtZnMtR3s98HzgAEBm3gU8qVuDUvfUGy0ABionFiKuHR50OrMkSZIkSVJJzDVErGfm0bKziKgB2Z0hqZsmQsRa9finM0O7EnHk8DiZ/hpIkiRJkiT1u7kmSf8YEb8JDEfEi4CPAX/bvWGpW+qNJsAJT2deOzzAWKPFkfHWfAxLkiRJkiRJi9hcQ8RLgd3AvwH/CbgG+K1uDUrdUy9CvxNZWAVgzfAAgIurSJIkSZIklcBcV2duRcQngU9m5u7uDknd9MR05hOvRAQYOTzGpjXLTnhckiRJkiRJWrxmLEeLtrdGxB5gJ7AzInZHxFsWZniabxPTmU90YZU1ywcBKxElSZIkSZLKYLY5rW+kvSrzD2bmyZl5MvAc4PkR8cauj07zbr4WVlm1rEYlcIVmSZIkSZKkEpgtSXoN8MrMvGeiITPvBl4N/Hw3B6bueOKdiCdWiViJYPXwgJWIkiRJkiRJJTBbiDiQmXsmNxbvRRzozpDUTU+sznxilYjQfi+ilYiSJEmSJEn9b7Ykaew492mROjqd+QQrEaG9QvP+w/4aSJIkSZIk9bvZVmd+ZkQcmKI9AJfkXYLma3VmgLXLB/nmgwdoZVKJE+9PkiRJkiRJi9OMIWJmVhdqIFoY9fGJ1ZlPfDrzmuEBmpkcPNJg9bCz2yVJkiRJkvrViSdJWlLmtRKxCA5dXEWSJEmSJKm/GSKWzBPvRJyHSsTl7RBxxBBRkiRJkiSprxkilswTqzPPRyXiIAD7R11cRZIkSZIkqZ8ZIpZMfXz+VmdeNlBhsFaxElGSJEmSJKnPGSKWTL3RYrBWIeZhNeWIYO3wACOjhoiSJEmSJEn9zBCxZMYaLYZq8/djXzM84MIqkiRJkiRJfc4QsWTqjSZDteq89bd2+YDTmSVJkiRJkvqcIWLJ1LtQiXio3mC82Zq3PiVJkiRJkrS4GCKWzHyHiBMrNB+wGlGSJEmSJKlvGSKWTH28yeB8ViIuHwBwSrMkSZIkSVIfM0QsmXqjxdDAPL4TcbgdIu53hWZJkiRJkqS+1dUQMSIuiIidEbErIi6dYv9QRFxZ7L8+IrZ27Htz0b4zIl5yDH3+UUQc7NpNLXHthVXm78e+eniiEnFs3vqUJEmSJEnS4tK1EDEiqsB7gJcC24FXRsT2SYe9FtiXmWcC7wbeWZy7HbgYOAe4AHhvRFRn6zMizgVO6tY99YP5fifiQLXCiqEa+53OLEmSJEmS1Le6WYl4HrArM+/OzDHgCuDCScdcCFxebF8NnB8RUbRfkZn1zLwH2FX0N22fRcD4/wO/3sV7WvLq4y2GavM3nRnaU5pHnM4sSZIkSZLUt7oZIm4G7u/4/EDRNuUxmdkA9gPrZjh3pj7fAOzIzIfmafx9qd5oMjQwvz/2NcMDViJKkiRJkiT1sb5YWCUiTgVeDvzxHI59XUTcFBE37d69u/uDW2TmezozwNrlA4wcHicz57VfSZIkSZIkLQ7dDBEfBE7r+LylaJvymIioAWuAvTOcO1379wNnArsi4l5geUTsmmpQmfm+zDw3M8/dsGHD8d3ZEtYOEed/OvNYo8WR8da89itJkiRJkqTFoZsh4o3Atog4IyIGaS+UsmPSMTuAS4rti4Drsl3OtgO4uFi9+QxgG3DDdH1m5t9l5qbM3JqZW4HRYrEWTVIfn9/VmQHWLB8EXKFZkiRJkiSpX9W61XFmNiLiDcBngCrwwcy8NSLeDtyUmTuADwAfLqoGH6MdClIcdxVwG9AAXp+ZTYCp+uzWPfSjeqM17+9EXDs8AMB+F1eRJEmSJEnqS10LEQEy8xrgmkltb+nYPkL7XYZTnXsZcNlc+pzimJXHM95+l5ldmc68Znk7RNw3aiWiJEmSJElSP+qLhVU0N2PN9jsL53s686qhGssGKjxyoD6v/UqSJEmSJGlxMEQskXqjOyFiRLBp9TIePnBkXvuVJEmSJEnS4mCIWCL1YvXkoYH5nc4MsGnNMh45cIT2ujiSJEmSJEnqJ4aIJVJvNIH5r0QE2Lh6GfVGiwf2HZ73viVJkiRJktRbhogl0q3pzACbVi8DYOfDj89735IkSZIkSeotQ8QSOTqdeZ5XZ4Z2JSLAzkcMESVJkiRJkvqNIWKJHJ3OPDD/P/ZlA1VOWj7A7Q8dmPe+JUmSJEmS1FuGiCUy1sXpzNCuRnQ6syRJkiRJUv8xRCyRJ96JOP/TmaG9QvPdew4drXiUJEmSJElSfzBELJFuLqwC7cVVmq1k16MHu9K/JEmSJEmSesMQsUQmKgSXdeGdiOAKzZIkSZIkSf3KELFEurk6M8C6lUMM1iqGiJIkSZIkSX3GELFEuj2duVoJztywktsNESVJkiRJkvqKIWKJTExn7lYlIsDZp6xi58MHuta/JEmSJEmSFp4hYolMVCIOdqkSEeDsTat45ECdfYfGunYNSZIkSZIkLSxDxBKZeCdiN0PEszatBuAOpzRLkiRJkiT1DUPEEhkdbzBYq1CtRNeu8fRNqwCc0ixJkiRJktRHDBFLZP/oOGuHB7p6jQ2rhjhp+YCViJIkSZIkSX3EELFERkbHWbu8uyFiRHDWplWGiJIkSZIkSX3EELFERg6PsXb5YNevc/am1dz5yOO0Wtn1a0mSJEmSJKn7DBFLZGQBpjNDe4Xm0bEm9+8b7fq1JEmSJEmS1H2GiCWyENOZAc4qFldxSrMkSZIkSVJ/MEQskX2jY5y0ANOZn7ZxFRGw0xBRkiRJkiSpLxgilsSR8Sb1Ros1C1CJuGKoxpNPXs4dDx/o+rUkSZIkSZLUfYaIJTEyOg6wIJWIAGdtdIVmSZIkSZKkfmGIWBL7RscAFmRhFYCzT1nNvXsOcWS8uSDXkyRJkiRJUvcYIpbERCXiQkxnhvYKza2Eux45uCDXkyRJkiRJUvcYIpbESFGJuGDTmY+u0Ox7ESVJkiRJkpY6Q8SSGDncrkRcu0CViFvXrWCoVnGFZkmSJEmSpD5giFgSE9OZ1w4vTCVitRI8zcVVJEmSJEmS+oIhYkmMjI4xVKswPFhdsGuetckQUZIkSZIkqR8YIpbEyOj4gk1lnvB9W9aw52Cde/YcWtDrSpIkSZIkaX4ZIpbEyOGxBVtUZcILz34SANfe9vCCXleSJEmSJEnzyxCxJPaNjrNmeGErEbectJxzTl3NZ299ZEGvK0mSJEmSpPlliFgS+3swnRngRds3cvO397H78fqCX1uSJEmSJEnzwxCxJPaNLvx0ZoAXb99EJnz+dqsRJUmSJEmSlipDxBLITEYOj7OmB5WITz9lFVtOGuba2wwRJUmSJEmSlipDxBI4Mt5irNFi7fDCVyJGBC/evol/2rWHQ/XGgl9fkiRJkiRJJ84QsQT2jY4BcFIPKhGh/V7EsUaLL925uyfXlyRJkiRJ0okxRCyBkdFxgJ4srALwg1tPYu3yAT7rlGZJkiRJkqQlyRCxBEaKSsS1PVhYBaBWrXD+2Ru57o5HGW+2ejIGSZIkSZIkHb+uhogRcUFE7IyIXRFx6RT7hyLiymL/9RGxtWPfm4v2nRHxktn6jIiPFO3fjIgPRkRvyu4WoZHDva1EhPaU5v2Hx7nxnsd6NgZJkiRJkiQdn66FiBFRBd4DvBTYDrwyIrZPOuy1wL7MPBN4N/DO4tztwMXAOcAFwHsjojpLnx8BzgaeAQwDv9Ste1tqjk5n7sHCKhN+9GnrGapVnNIsSZIkSZK0BHWzEvE8YFdm3p2ZY8AVwIWTjrkQuLzYvho4PyKiaL8iM+uZeQ+wq+hv2j4z85osADcAW7p4b0vKvqPTmXtXibh8sMaPbNvAtbc9QvtHJEmSJEmSpKWimyHiZuD+js8PFG1THpOZDWA/sG6Gc2fts5jG/BrgH074DvrE/sPjLBuosGyg2tNxvHj7Rh4cOcyt3znQ03FIkiRJkiTp2PTjwirvBb6Umf801c6IeF1E3BQRN+3evXuBh9Yb+w6N9XQq84Tzn/4kKoFTmiVJkiRJkpaYboaIDwKndXzeUrRNeUxE1IA1wN4Zzp2xz4j4bWAD8KbpBpWZ78vMczPz3A0bNhzjLS1NI4fHezqVecK6lUOce/rJfPbWh3s9FEmSJEmSJB2DWhf7vhHYFhFn0A76LgZeNemYHcAlwFeAi4DrMjMjYgfw0Yh4F3AqsI32ew5juj4j4peAlwDnZ2ari/e15OwfXbgQ8aPXf3vG/etWDnLDvY/xJ9ft4uQVc6+OfNVznnyiQ5MkSZIkSdJx6lolYvGOwzcAnwFuB67KzFsj4u0R8bLisA8A6yJiF+3qwUuLc28FrgJuo/1uw9dnZnO6Pou+/gzYCHwlIm6JiLd0696Wmn2jY5y0vPfTmQG2n7IagNse8r2IkiRJkiRJS0U3KxHJzGuAaya1vaVj+wjw8mnOvQy4bC59Fu1dvZelbLFMZ4b2lOZT1y7j+rv38rynrKNaiV4PSZIkSZIkSbPox4VV1CEz2T86zppFsLDKhBeetZG9h8b4+rf39XookiRJkiRJmgNDxD43OtZkrNnipEVSiQjw9FNWseWkYa6741EaTV9fKUmSJEmStNgZIva5kcPjAItmOjNARPCi7RsZOTzODfc+1uvhSJIkSZIkaRaGiH1u36ExANYukoVVJpy5YSVnrF/BF3fuZqxhNaIkSZIkSdJiZojY5/ZPVCIOL55KRGhXI754+0YO1ht85e69vR6OJEmSJEmSZmCI2OdGRiemMy+uSkSA09et4GkbV/KlO3dzZLzZ6+FIkiRJkiRpGoaIfW7faHs682JaWKXTi7Zv4vB4ky/v2tProUiSJEmSJGkahoh9bmI68+pFNp15wua1w5xz6mq+vGsPh+qNXg9HkiRJkiRJUzBE7HP7Do0xPFBl2UC110OZ1o8/fSPjjRZfunN3r4ciSZIkSZKkKRgi9rmRw+OLdirzhI2rl/Gs09bylbv3cqConJQkSZIkSdLiYYjY50ZGx1mzCBdVmeyFZz+JZiv552/5bkRJkiRJkqTFxhCxz42Mji36SkSAdSuHeMaWNdxwz2McHnOlZkmSJEmSpMXEELHPjRweZ+0SCBEBfnTbBuqNFtffs7fXQ5EkSZIkSVIHQ8Q+NzI6zprhxT+dGeDUtcNse9JK/uVbexlvtno9HEmSJEmSJBUMEftYZi6Z6cwTfvRpGzhYb/C1b+/r9VAkSZIkSZJUMETsY4fGmjRauWSmMwM8Zf0Ktpw0zJfv2kMrs9fDkSRJkiRJEoaIfW3foTEA1i6R6cwAEcGPbtvA3kNj3PqdA70ejiRJkiRJkjBE7Gv7D48DLKlKRIDtp65m3YpBvnTnbtJqREmSJEmSpJ4zROxjI6MTIeLSqUQEqBTViA+OHOZbuw/1ejiSJEmSJEmlZ4jYx/aNtqczL6WFVSY868lrWTVU40t37u71UCRJkiRJkkrPELGPjRTTmdcswRBxoFrh+WeuZ9fugzy473CvhyNJkiRJklRqhoh9bGQJLqzS6bwzTmaoVuFLd1mNKEmSJEmS1EuGiH1s5PA4KwarDNaW5o952UCVH9x6Mrd+Zz97D9Z7PRxJkiRJkqTSWprpkuZkZHR8yS2qMtkPnH4SrYRP3fKdXg9FkiRJkiSptAwR+9jI6Bhrl+D7EDttWr2MzWuH+djND/R6KJIkSZIkSaVliNjHRg6PL/kQEdrViLc/dIBbv7O/10ORJEmSJEkqJUPEPrZvdGzJLqrS6Zlb1jBYrXC11YiSJEmSJEk9YYjYx/aP9kcl4vLBGi/avpFP3fIdxhqtXg9HkiRJkiSpdAwR+1Rm9s10ZoCLnr2Fxw6N8YWdj/Z6KJIkSZIkSaVjiNinHq83aLayL6YzA/zItvVsWDXEx25ySrMkSZIkSdJCM0TsU/tHxwH6phKxVq3ws9+/mS/sfJTdj9d7PRxJkiRJkqRSMUTsUyNHQ8T+qESE9pTmZiv51C0P9nookiRJkiRJpWKI2Kf2jY4BcFKfVCICbNu4imeetparb36AzOz1cCRJkiRJkkrDELFPjRzur+nMEy569hbuePhxbv3OgV4PRZIkSZIkqTQMEfvUSFGJuKZPFlaZ8LLvO5XBaoWrb3aBFUmSJEmSpIViiNinRvpsYZUJa5YP8KJzNvLJWx6k3mj2ejiSJEmSJEmlYIjYp0ZGx1k5VGOg2n8/4pc/ewsjo+P8/mfv5MCR8V4PR5IkSZIkqe/1X8IkoD2dec1wf1UhTviRbRt4yTkbed+X7ub5v3sdv/v3t/PogSO9HpYkSZIkSVLfqvV6AOqOkcPjnLSiP0PEaiX489ecyzcf3M+f/eO3eP+X7uYvvnwvP/sDm/nlH30KT92wstdDlCRJkiRJ6iuGiH1q3+gYa/toUZWPXv/tKdt/6KnrOWvjKr68aw9X3/wAV9x4PxtXD3H2ptWcvWkVp528nErEtP2+6jlP7taQJUmSJEmS+oYhYp/aPzrO5rXDvR7Ggli3cogLn7WZF579JL7xwH7ueOgA/3TXbv7xzt2sGKxy1qZVPGnVMqqVoBJQqQTVCGrV4KxNK3nK+pWctKJ/AldJkiRJkqT51tUQMSIuAP4QqAL/OzPfMWn/EPAh4NnAXuAVmXlvse/NwGuBJvArmfmZmfqMiDOAK4B1wM3AazJzrJv3t5iNHB7vu5WZZ7Nq2QA/fOZ6fvjM9Rwea3Lno4+z8+HHuf2hx/nat0emPOeqmx4A4OQVgzxl/QqesmEFp69bwYaVQ6xfNciGlctYv2qQdSuGGKz5ClFJkiRJklROXQsRI6IKvAd4EfAAcGNE7MjM2zoOey2wLzPPjIiLgXcCr4iI7cDFwDnAqcDnIuJpxTnT9flO4N2ZeUVE/FnR95926/4Ws1YrGemz6czHaniwyjO3rOWZW9bSymS82aLVgmYmrVbSymSs2eIZm9dw9+5D3L3nIN969BDX3fEoew5OnT0PVisMVIOBWoWBauWJz9X254FahcHi8/BAldXDA6xaVmP1sgFWD7e/nrxikA2rhli/cogNq4ZYNlBd4O+MJEmSJEnSsetmJeJ5wK7MvBsgIq4ALgQ6Q8QLgbcW21cDfxIRUbRfkZl14J6I2FX0x1R9RsTtwAuBVxXHXF70W8oQ8fF6g1ZSukrE6VQiGKpNHdY9cqDOiqEaz9i8lmdsXgvAWKPFwXqj/e9Ig8fr4xysN2g0k2YrabTaX9v/Wke3D481eLyVNJvJiqEadz76OAcON3j8yDitnHpsK4dqrBkeYKAaVCtBrVJpfz36+bvbB6rtexkaqLBsoMpQrf11Wa3KsqJt2dF91aPnV4q+KtH+XK20vy+1SoVKhWKq93e/O3LymyQ7d1ciGKxVGKxVGKpWGai1w9NmK6k3Wow1Wow1W9THm7QynwhaO4JXgEarHeoe/Z5mUo2gUqF9zxFUq+3p59WJewmIGd5zqe+WOc0v39H9s5wPNFotGs0nfk6NVovMid+h9u9XtXhNQKXC0Z+XPydJkiRJ6h/dDBE3A/d3fH4AeM50x2RmIyL2056OvBn46qRzNxfbU/W5DhjJzMYUx5fO/tFxANYuL28l4okYrFU4uTbIyfP0nsTMZKzR4vB487vCyYntw2NNEmgWFZKthPp4i1ZmUTlJ0V4EOM1kvNVivJk0mu1wpzlbEtRnJgKr70k6O83hW5KzHDSXgG3m82fpf9bzZzlgkYtoB4qV2X5Wx9rv/HXFfOacMY8jm99xSZIkSZpPv/Mz/46f+f4tvR7GgivdwioR8TrgdcXHgxGxs5fj6aaXv3PG3euBPXPp5+c4/XsbnztFm6RjMednUNK88/mTestnUOotn0HpBP3s/zih0xf7Mzht4NPNEPFB4LSOz1uKtqmOeSAiasAa2guszHTuVO17gbURUSuqEae6FgCZ+T7gfcdzQ/0kIm7KzHN7PQ6prHwGpd7x+ZN6y2dQ6i2fQam3lvIz2M3lZm8EtkXEGRExSHuhlB2TjtkBXFJsXwRcl+35fzuAiyNiqFh1eRtww3R9Fud8oeiDos9PdfHeJEmSJEmSpNLoWiVi8Y7DNwCfAarABzPz1oh4O3BTZu4APgB8uFg45THaoSDFcVfRXoSlAbw+M5sAU/VZXPI3gCsi4neArxd9S5IkSZIkSTpBMduL/9WfIuJ1xdRuST3gMyj1js+f1Fs+g1Jv+QxKvbWUn0FDREmSJEmSJEkz6uY7ESVJkiRJkiT1AUPEkomICyJiZ0TsiohLez0eaSmLiA9GxKMR8c2OtpMj4tqIuKv4elLRHhHxR8Wz968R8QMd51xSHH9XRFzS0f7siPi34pw/iohY2DuUFreIOC0ivhARt0XErRHxq0W7z6HUZRGxLCJuiIhvFM/f24r2MyLi+uKZubJYDJFiwcQri/brI2JrR19vLtp3RsRLOtr9u1WaRURUI+LrEfHp4rPPoLRAIuLe4u/EWyLipqKtr/8ONUQskYioAu8BXgpsB14ZEdt7OyppSftL4IJJbZcCn8/MbcDni8/Qfu62Ff9eB/wptP9HBvht4DnAecBvT/wPTXHML3ecN/laUtk1gP+emduB5wKvL/53zedQ6r468MLMfCbwLOCCiHgu8E7g3Zl5JrAPeG1x/GuBfUX7u4vjKJ7Zi4FzaD9f7y1CEf9ulebmV4HbOz77DEoL68cy81mZeW7xua//DjVELJfzgF2ZeXdmjgFXABf2eEzSkpWZX6K9snynC4HLi+3LgZ/uaP9Qtn0VWBsRpwAvAa7NzMcycx9wLe3/I3YKsDozv5rtl9d+qKMvSUBmPpSZXyu2H6f9f6I243ModV3xHB0sPg4U/xJ4IXB10T75+Zt4Lq8Gzi8qKi4ErsjMembeA+yi/Terf7dKs4iILcBPAP+7+Bz4DEq91td/hxoilstm4P6Ozw8UbZLmz8bMfKjYfhjYWGxP9/zN1P7AFO2SplBMy/p+4Hp8DqUFUVQr3QI8Svv/9HwLGMnMRnFI5zNz9Dkr9u8H1nHsz6WkJ/wB8OtAq/i8Dp9BaSEl8NmIuDkiXle09fXfobVeD0CS+lVmZkRkr8ch9buIWAn8DfDfMvNA5+tifA6l7snMJvCsiFgLfAI4u7cjksojIn4SeDQzb46IF/R4OFJZ/XBmPhgRTwKujYg7Onf249+hViKWy4PAaR2ftxRtkubPI0XpOcXXR4v26Z6/mdq3TNEuqUNEDNAOED+SmR8vmn0OpQWUmSPAF4Dn0Z6eNVGo0PnMHH3Oiv1rgL0c+3Mpqe35wMsi4l7aU41fCPwhPoPSgsnMB4uvj9L+j2nn0ed/hxoilsuNwLZixa5B2i/Q3dHjMUn9ZgcwsaLWJcCnOtp/vliV67nA/qLM/TPAiyPipOIFui8GPlPsOxARzy3eV/PzHX1J4ui7nz4A3J6Z7+rY5XModVlEbCgqEImIYeBFtN9L+gXgouKwyc/fxHN5EXBd8Y6nHcDFxcqxZ9B+cfwN+HerNKPMfHNmbsnMrbSfj+sy8+fwGZQWRESsiIhVE9u0/378Jn3+d6jTmUskMxsR8Qbav6RV4IOZeWuPhyUtWRHx18ALgPUR8QDtVbXeAVwVEa8F7gP+r+Lwa4D/QPtl1aPALwJk5mMR8T9o/6EG8PbMnFis5b/QXgF6GPj74p+kJzwfeA3wb8V72QB+E59DaSGcAlxerOBaAa7KzE9HxG3AFRHxO8DXaQf9FF8/HBG7aC9KdjFAZt4aEVcBt9Fecf31xTRp/LtVOi6/gc+gtBA2Ap8oXqNTAz6amf8QETfSx3+HRvs/PkiSJEmSJEnS1JzOLEmSJEmSJGlGhoiSJEmSJEmSZmSIKEmSJEmSJGlGhoiSJEmSJEmSZmSIKEmSJEmSJGlGhoiSJEk6bhHxgoj49AJf8zcX8nqSJEkyRJQkSVIPRUTtOE475hAxIqrHcR1JkiQVDBElSZL0XSJia0TcHhHvj4hbI+KzETEcEWdGxOci4hsR8bWIeGpxysqIuDoi7oiIj0REFP28JSJujIhvRsT7Otq/GBF/EBE3Ab8aET8VEddHxNeL/jcWx62MiL+IiH+LiH+NiP8YEe8AhiPiloj4SHHcqyPihqLtzycCw4g4GBG/HxHfAJ4XEe+IiNuKvv7XQn9fJUmSlrLIzF6PQZIkSYtIRGwFdgHnZuYtEXEVsAP4r8A7MvMTEbGM9n+QPg/4FHAO8B3gn4Ffy8wvR8TJmflY0eeHgasy828j4ovAbZn5X4p9JwEjmZkR8UvA0zPzv0fEO4GhzPxvE8dl5r6IOJiZK4u2pwO/B/xsZo5HxHuBr2bmhyIigVdk5lURsQ74F+Ds4jprM3Oky99KSZKkvnE800ckSZLU/+7JzFuK7ZuBM4DNmfkJgMw8AlAUF96QmQ8Un28BtgJfBn4sIn4dWA6cDNwK/G3R55Ud19oCXBkRpwCDwD1F+48DF08clJn7phjn+cCzgRuLsQwDjxb7msDfFNv7gSPAB4p3OC7oexwlSZKWOqczS5IkaSr1ju0msPYYjq0VlYrvBS7KzGcA7weWdRx3qGP7j4E/KY77T5OOm00Al2fms4p/Z2XmW4t9RzKzCZCZDdpVk1cDPwn8wzFcQ5IkqfQMESVJkjQXjwMPRMRPA0TEUEQsn+H4iSBwT0SsBC6a4dg1wIPF9iUd7dcCr5/4UEx7BhiPiIFi+/PARRHxpOKYkyPi9MkXKMawJjOvAd4IPHOG8UiSJGkSQ0RJkiTN1WuAX4mIf6X9fsFN0x1YvG/w/cA3gc8AN87Q71uBj0XEzcCejvbfAU4qFmb5BvBjRfv7gH+NiI9k5m3AbwGfLcZ1LXDKFNdYBXy6OObLwJtmuVdJkiR1cGEVSZIkSZIkSTOyElGSJEmSJEnSjAwRJUmSJEmSJM3IEFGSJEmSJEnSjAwRJUmSJEmSJM3IEFGSJEmSJEnSjAwRJUmSJEmSJM3IEFGSJEmSJEnSjAwRJUmSJEmSJM3o/wBZJQMesZtLcAAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"df.groupby('Categories').count()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.523851Z","iopub.execute_input":"2022-09-27T09:38:02.524192Z","iopub.status.idle":"2022-09-27T09:38:02.549701Z","shell.execute_reply.started":"2022-09-27T09:38:02.524158Z","shell.execute_reply":"2022-09-27T09:38:02.548670Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                        Description  ncharacters\nCategories                                      \nBooks                         11820        11820\nClothing & Accessories         8670         8670\nElectronics                   10621        10621\nHousehold                     19313        19313","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>ncharacters</th>\n    </tr>\n    <tr>\n      <th>Categories</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Books</th>\n      <td>11820</td>\n      <td>11820</td>\n    </tr>\n    <tr>\n      <th>Clothing &amp; Accessories</th>\n      <td>8670</td>\n      <td>8670</td>\n    </tr>\n    <tr>\n      <th>Electronics</th>\n      <td>10621</td>\n      <td>10621</td>\n    </tr>\n    <tr>\n      <th>Household</th>\n      <td>19313</td>\n      <td>19313</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X=df.drop('Categories',axis=1)\ny=df.Categories","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.551178Z","iopub.execute_input":"2022-09-27T09:38:02.551627Z","iopub.status.idle":"2022-09-27T09:38:02.558508Z","shell.execute_reply.started":"2022-09-27T09:38:02.551590Z","shell.execute_reply":"2022-09-27T09:38:02.557426Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class config:\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    seed = 42   \n    save_dir=\"./\"\n    \n    #tokenizer params\n    truncation = True \n    padding = True\n    max_length = 1024\n    \n    # model params\n    model_name = \"microsoft/deberta-v3-base\"\n    #training params\n    learning_rate = 2e-6\n    batch_size = 2\n    epochs = 5\n    NFOLDS = 5\n    \nTOKENIZERS_PARALLELISM=True    ","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.560110Z","iopub.execute_input":"2022-09-27T09:38:02.560661Z","iopub.status.idle":"2022-09-27T09:38:02.623180Z","shell.execute_reply.started":"2022-09-27T09:38:02.560625Z","shell.execute_reply":"2022-09-27T09:38:02.622334Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=config.NFOLDS,shuffle=True,random_state=42)\ndf[\"fold\"] = -1\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df, df[\"Categories\"] )):\n    df.loc[val_idx, \"fold\"] = fold\n","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.627149Z","iopub.execute_input":"2022-09-27T09:38:02.627449Z","iopub.status.idle":"2022-09-27T09:38:02.672136Z","shell.execute_reply.started":"2022-09-27T09:38:02.627422Z","shell.execute_reply":"2022-09-27T09:38:02.671317Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.groupby('fold').count()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.673378Z","iopub.execute_input":"2022-09-27T09:38:02.673725Z","iopub.status.idle":"2022-09-27T09:38:02.697080Z","shell.execute_reply.started":"2022-09-27T09:38:02.673693Z","shell.execute_reply":"2022-09-27T09:38:02.695974Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"      Categories  Description  ncharacters\nfold                                      \n0          10085        10085        10085\n1          10085        10085        10085\n2          10085        10085        10085\n3          10085        10085        10085\n4          10084        10084        10084","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Categories</th>\n      <th>Description</th>\n      <th>ncharacters</th>\n    </tr>\n    <tr>\n      <th>fold</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10085</td>\n      <td>10085</td>\n      <td>10085</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10085</td>\n      <td>10085</td>\n      <td>10085</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10085</td>\n      <td>10085</td>\n      <td>10085</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10085</td>\n      <td>10085</td>\n      <td>10085</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10084</td>\n      <td>10084</td>\n      <td>10084</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.698720Z","iopub.execute_input":"2022-09-27T09:38:02.699132Z","iopub.status.idle":"2022-09-27T09:38:02.707002Z","shell.execute_reply.started":"2022-09-27T09:38:02.699097Z","shell.execute_reply":"2022-09-27T09:38:02.706252Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name)\ntokenizer.save_pretrained(config.save_dir+'tokenizer/')\nconfig.tokenizer = tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:02.708136Z","iopub.execute_input":"2022-09-27T09:38:02.709052Z","iopub.status.idle":"2022-09-27T09:38:10.950156Z","shell.execute_reply.started":"2022-09-27T09:38:02.709014Z","shell.execute_reply":"2022-09-27T09:38:10.949180Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bda0a3346ae94092abbbdb5c90583094"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75239bc049ab41298a55bd58ad932244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0319278eb684f838ab09cf701b96ca6"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:10.951790Z","iopub.execute_input":"2022-09-27T09:38:10.952172Z","iopub.status.idle":"2022-09-27T09:38:10.957356Z","shell.execute_reply.started":"2022-09-27T09:38:10.952136Z","shell.execute_reply":"2022-09-27T09:38:10.956334Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(config.model_name,num_labels=4)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:38:10.959127Z","iopub.execute_input":"2022-09-27T09:38:10.959498Z","iopub.status.idle":"2022-09-27T09:39:15.345337Z","shell.execute_reply.started":"2022-09-27T09:38:10.959464Z","shell.execute_reply":"2022-09-27T09:39:15.344224Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc5c53a204f246a2a2e414a0194c2eb0"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (1): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (2): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (3): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (4): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (5): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (6): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (7): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (8): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (9): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (10): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (11): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=768, out_features=4, bias=True)\n  (dropout): StableDropout()\n)"},"metadata":{}}]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val\n                in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.346685Z","iopub.execute_input":"2022-09-27T09:39:15.347950Z","iopub.status.idle":"2022-09-27T09:39:15.355311Z","shell.execute_reply.started":"2022-09-27T09:39:15.347910Z","shell.execute_reply":"2022-09-27T09:39:15.354144Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p):\n    prediction, labels = p\n    preds_flat = np.argmax(prediction, axis=1).flatten()\n    labels_flat = labels.flatten()\n    f1 = f1_score(labels_flat, preds_flat, average='macro')\n    return {\"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.356787Z","iopub.execute_input":"2022-09-27T09:39:15.357208Z","iopub.status.idle":"2022-09-27T09:39:15.368955Z","shell.execute_reply.started":"2022-09-27T09:39:15.357175Z","shell.execute_reply":"2022-09-27T09:39:15.367962Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"descriptions = df[\"Description\"].map(str).values.tolist()\nlabels = df[\"Categories\"].values.tolist()\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.370593Z","iopub.execute_input":"2022-09-27T09:39:15.370922Z","iopub.status.idle":"2022-09-27T09:39:15.418074Z","shell.execute_reply.started":"2022-09-27T09:39:15.370891Z","shell.execute_reply":"2022-09-27T09:39:15.417212Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_batch_tokenizer(tokenizer, dataset):\n    return tokenizer.batch_encode_plus(dataset,\n                                       max_length=512,\n                                       padding=True,\n                                       truncation=True,\n                                       add_special_tokens=True,\n                                       return_attention_mask=True,\n                                       return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.419189Z","iopub.execute_input":"2022-09-27T09:39:15.420182Z","iopub.status.idle":"2022-09-27T09:39:15.425678Z","shell.execute_reply.started":"2022-09-27T09:39:15.420155Z","shell.execute_reply":"2022-09-27T09:39:15.424652Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(descriptions, labels, test_size=0.4, stratify=labels, random_state=42)\nx_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.426908Z","iopub.execute_input":"2022-09-27T09:39:15.427719Z","iopub.status.idle":"2022-09-27T09:39:15.476530Z","shell.execute_reply.started":"2022-09-27T09:39:15.427685Z","shell.execute_reply":"2022-09-27T09:39:15.475636Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.482605Z","iopub.execute_input":"2022-09-27T09:39:15.484528Z","iopub.status.idle":"2022-09-27T09:39:15.489548Z","shell.execute_reply.started":"2022-09-27T09:39:15.484501Z","shell.execute_reply":"2022-09-27T09:39:15.488685Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#    valid_labels = valid_folds[CFG.target_cols].values\n#x_train, x_valid, y_train, y_valid = train_test_split(descriptions,labels, test_size=0.3, stratify=labels, random_state=42)\n#x _valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\nx_train_tokens = get_batch_tokenizer(tokenizer, x_train)\nx_valid_tokens = get_batch_tokenizer(tokenizer, x_valid)\nx_test_tokens = get_batch_tokenizer(tokenizer, x_test)\n#y_train = df['Category']\n#y_valid = df['Category']\ntrain_dataset = Dataset(x_train_tokens, y_train)\nvalid_dataset = Dataset(x_valid_tokens, y_valid)\ntest_dataset = Dataset(x_test_tokens, y_test)\ngc.collect() \n\nargs = TrainingArguments(output_dir=\"output\",\n                            evaluation_strategy=\"epoch\",\n                            metric_for_best_model=\"f1\",\n                            save_strategy=\"epoch\",\n                            num_train_epochs=config.epochs,\n                            load_best_model_at_end=True\n                         \n                            )\ntrainer = Trainer(args=args,\n                    model=model,\n                    train_dataset=train_dataset,\n                    eval_dataset=valid_dataset,\n                    compute_metrics=compute_metrics,\n                    callbacks=[EarlyStoppingCallback(\n                            early_stopping_patience=3)]\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:15.490837Z","iopub.execute_input":"2022-09-27T09:39:15.491330Z","iopub.status.idle":"2022-09-27T09:39:40.114483Z","shell.execute_reply.started":"2022-09-27T09:39:15.491282Z","shell.execute_reply":"2022-09-27T09:39:40.113551Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T09:39:40.115729Z","iopub.execute_input":"2022-09-27T09:39:40.116681Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 30254\n  Num Epochs = 5\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 18910\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='257' max='18910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  257/18910 02:51 < 3:29:11, 1.49 it/s, Epoch 0.07/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Trainer(model=model)\npredictions = trainer.predict(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.argmax(predictions.predictions, axis=1).flatten()\ntrue_vals = predictions.label_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(true_vals, preds, target_names=list(le.classes_)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}